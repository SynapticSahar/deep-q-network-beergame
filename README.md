# Deep Q Network For BeerGame


• Implemented Q-learning with Deep Neural Networks to approximate Q-values,target network
to to provide steady Q-value predictions, experience replay buffer to stabilize and improve <br/>
the efficiency, and shaped reward to prioritize system-wide objectives over local ones <br/>
• Transfer learning is applied to reduce training time for different agents <br/>
• achieved near-optimal order quantities when playing with agents using base-stock policies <br/>
and surpassed base-stock policies with Sterman co-players.

Initially, encountering this repository was both exciting and challenging.<br/>
The provided code did not function as intended at first, prompting me to deeply understand and enhance its functionality and made several
enhancements and modifications.<br/>
This repository hosts the refined version of the code with enhancements to ensure its operational integrity for scholarly or developmental pursuits.<br/>

main reference: https://doi.org/10.48550/arXiv.1708.05924

